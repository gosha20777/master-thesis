\section{Доменная адаптация}\label{sect-3}

Последнее время приложения компьютерного зрения (CV) претерпевают революционные изменения благодаря методам глубокого обучения, которые, используя огромные объемы данных, успешно решают сложные задачи с высокой точностью. Несмотря на высокую эффективность распознавания, модели глубокого обучения, как результат использования определенных наборов данных, имеют тенденцию к смещению в область, из которой были получены эти данные. Это приводит к существенному снижению производительности моделей при тестировании на наборах данных из разных доменов. Приминительно к выйчслительной фотографии проблема даменной адаптации стоит особенно остро в силу уникальности каждого сенсора и его специфических особенностей. В добавок сбор крупномосштабного набора данных требует от производителя конечного утсройства занчительных финансовых затрат, что значительно увеличивает стоимость выпуска каждого нового устройства.

Одним из примитивных решений этой проблемы является адаптация модели к новой, или целевой области, путем переобучения модели на данных, принадлежащих к этой области. Однако, сбор новых данных и переобучение всей модели может быть трудным, дорогостоящим или даже невозможным. 

В связи с этим, лучшим подходом является сохранение полученных знаний в основной области, а затем передача этих знаний в целевую область, где нужно выполнить те же задачи, но с потенциально другим распределением данных. Это позволяет снизить затраты на повторный сбор данных и их маркировку.

\addimghere{1-4-domain-adaptation}{0.7}{Визуализация доменной адаптации.}{domain-adaptation}

Более формальное определение доменной адаптации следующее. Пусть заданы два домена $D_s$ и $D_t$, имеющие пространства признаков $X_s$ и $X_t$ соответственно, причем распределения этих пространств различны: $P(X_s) \neq P(X_t)$. Пусть $Y_s$ и $Y_t$ -- пространства меток для исходного и целевого доменов соответственно. Пусть функция $f: X_s \rightarrow Y_s$ определяет отображение признаков в исходном домене в метки, а функция $h: X_t \rightarrow Y_t$ -- функция классификации в целевом домене. Обозначим обучающую выборку исходного домена $D_s = (x_i, y_i)$, $i=\overline{1, n_s}$, где $x_i \in X_s$, а $y_i \in Y_s$. Аналогично, обучающая выборка целевого домена состоит из размеченной выборки $D_t^l =(x_i, y_i)$, $i=\overline{1, n_t^l}$ и неразмеченной $D_t^u = (x_i)$ , $i=\overline{1, n_t^u}$, где $x_i \in X_t$ и $y_i \in Y_t$ для размеченной выборки. Отметим, что размер размеченной выборки мал: $n_t^l \ll n_t^u$. 

Задача доменной адаптации с несколькими примерами (few-shot domain adaptation) состоит в том, чтобы достичь высокой точности аппроксимации $h$, используя $D_t^l$, при условии, что модель способна аппроксимировать $f$. Другими словами, в случае имеющихся лишь нескольких размеченных примеров из целевого домена $D_t^l$, необходимо адаптировать модель, обученную на исходном домене $D_s$, таким образом, чтобы она показывала высокую производительность на выборке целевого домена $D_t$ (рис. \ref{domain-adaptation}).

\input{inc/3-1-reverse-gradient} % Reverse gradient