\paragraph{$L_1$ норма}

В данной работе мы применяем $L_1$ норму как функцию потерь, так как она позволяет надежно контролировать оптимизацию значений пикселей в процессе обучения сети. Эта потеря определяется как сумма абсолютных разностей между предсказанным изображением $\hat{I}$ и истинным RGB-изображением $I$. Она является чувствительной к малым различиям между соответствующими пикселями и может эффективно сглаживать текстуры и убирать шум, за счет чего, применение данной функции потерь довольно популярно при обучении нейросетевых конвейеров обработки изображений.

Кроме того, мы не используем эту потерю при доменной адаптации. Это делается для того, чтобы избежать переобучения нейронной сети на конкретные данные и обеспечить ее способность к обобщению на новые данные, так как размер размеченой выбрки целевого домена мал.
